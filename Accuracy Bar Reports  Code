import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
import numpy as np
import matplotlib.pyplot as plt

# =======================
# 1. Load Dataset
# =======================
df = pd.read_csv("dataset2.csv")

# Target column (Objective)
y = df["What are your savings objectives?"]
X = df.drop(columns=["What are your savings objectives?"])

# =======================
# 2. Preprocessing
# =======================
cat_features = X.select_dtypes(include=["object"]).columns.tolist()
num_features = X.select_dtypes(exclude=["object"]).columns.tolist()

preprocessor = ColumnTransformer(
    transformers=[
        ("cat", OneHotEncoder(handle_unknown="ignore"), cat_features),
        ("num", StandardScaler(), num_features)
    ]
)

# =======================
# 3. Define Models
# =======================
models = {
    "Naive Bayes": GaussianNB(),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42, n_estimators=100),
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "SVM": SVC(kernel="rbf", probability=True, random_state=42)
}

# =======================
# 4. Train/Test Split
# =======================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# =======================
# 5. Holdout Test Results
# =======================
print("\n=== Holdout Test Results ===\n")
holdout_results = {}

for name, model in models.items():
    clf = Pipeline(steps=[("preprocessor", preprocessor),
                         ("classifier", model)])
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    
    acc = accuracy_score(y_test, y_pred)
    holdout_results[name] = acc
    
    print(f"Model: {name}")
    print("Accuracy :", acc)
    print("Precision:", precision_score(y_test, y_pred, average="weighted", zero_division=0))
    print("Recall   :", recall_score(y_test, y_pred, average="weighted", zero_division=0))
    print("F1 Score :", f1_score(y_test, y_pred, average="weighted", zero_division=0))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("-" * 50)

    # Save Confusion Matrix Plot
    cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)
    disp.plot(cmap="Blues", xticks_rotation=45)
    plt.title(f"Confusion Matrix - {name}")
    plt.tight_layout()
    plt.savefig(f"confusion_matrix_{name.replace(' ', '_').lower()}.png", dpi=300)
    plt.close()

# =======================
# 6. Cross-Validation Results
# =======================
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_results = {}

print("\n=== 5-Fold Cross-Validation Results ===\n")
for name, model in models.items():
    clf = Pipeline(steps=[("preprocessor", preprocessor),
                         ("classifier", model)])
    scores = cross_val_score(clf, X, y, cv=cv, scoring="accuracy")
    cv_results[name] = np.mean(scores)
    
    print(f"Model: {name}")
    print("CV Mean Accuracy:", np.mean(scores))
    print("CV Std Dev      :", np.std(scores))
    print("Fold Scores     :", scores)
    print("-" * 50)

# =======================
# 7. Visualization (Bar + Pie)
# =======================
# ---- Holdout Bar ----
plt.figure(figsize=(8,6))
plt.bar(holdout_results.keys(), holdout_results.values(), color="skyblue")
plt.title("Holdout Test Accuracy (Bar Chart)")
plt.ylabel("Accuracy")
plt.xticks(rotation=30)
plt.tight_layout()
plt.savefig("holdout_accuracy_bar.png", dpi=300)
plt.show()

# ---- Holdout Pie ----
plt.figure(figsize=(8,6))
plt.pie(holdout_results.values(), labels=holdout_results.keys(), autopct='%1.1f%%', startangle=140)
plt.title("Holdout Test Accuracy (Pie Chart)")
plt.tight_layout()
plt.savefig("holdout_accuracy_pie.png", dpi=300)
plt.show()

# ---- CV Bar ----
plt.figure(figsize=(8,6))
plt.bar(cv_results.keys(), cv_results.values(), color="lightgreen")
plt.title("Cross-Validation Accuracy (Bar Chart)")
plt.ylabel("Accuracy")
plt.xticks(rotation=30)
plt.tight_layout()
plt.savefig("cv_accuracy_bar.png", dpi=300)
plt.show()

# ---- CV Pie ----
plt.figure(figsize=(8,6))
plt.pie(cv_results.values(), labels=cv_results.keys(), autopct='%1.1f%%', startangle=140)
plt.title("Cross-Validation Accuracy (Pie Chart)")
plt.tight_layout()
plt.savefig("cv_accuracy_pie.png", dpi=300)
plt.show()

print("\nâœ… All visualizations saved:")
print(" - holdout_accuracy_bar.png")
print(" - holdout_accuracy_pie.png")
print(" - cv_accuracy_bar.png")
print(" - cv_accuracy_pie.png")
print(" - confusion_matrix_<model>.png (for each model)")
